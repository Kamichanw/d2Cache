import subprocess
import time
import os
from collections import deque
import argparse
import shlex

# --- ä»»åŠ¡ç”Ÿæˆå‡½æ•° (å·²æŒ‰è¦æ±‚ä¿®æ”¹) ---

def generate_tasks(gpus_per_task, run_dir):
    """æ ¹æ®æ–°çš„å®éªŒè®¾è®¡, æ˜¾å¼ç”Ÿæˆæ‰€æœ‰ç‹¬ç«‹çš„å‘½ä»¤è¡Œä»»åŠ¡"""
    tasks = deque()
    base_command = f"accelerate launch --num_machines 1 --num_processes {gpus_per_task} eval.py"
    
    # --- éå¸¸é€šç”¨çš„å‚æ•°ï¼Œæ‰€æœ‰å®éªŒå…±äº« ---
    common_args = "batch_size=1 seed=1234 generation=vanilla"

    # ==========================================================================
    # å®éªŒä¸€: ç½‘æ ¼æœç´¢ cache.rollout_p å’Œ cache.current_k
    # ==========================================================================
    print("--- æ­£åœ¨ç”Ÿæˆ [å®éªŒä¸€: ç½‘æ ¼æœç´¢ rollout_p å’Œ current_k] ä»»åŠ¡ ---")
    # å®éªŒä¸€å›ºå®šæ¨¡å‹ã€ç¼“å­˜å’Œæ•°æ®é›†
    exp1_base_args = f"{common_args} model=dream-inst cache=d2cache dataset.name=humaneval"
    gen_lengths_exp1 = [256, 1024]
    rollout_ps = [0.05, 0.1, 0.2, 0.4]
    current_ks = [16, 24, 32, 40]

    for length in gen_lengths_exp1:
        for p in rollout_ps:
            for k in current_ks:
                task_name = f"exp1_pk_search/len{length}/p{p}_k{k}"
                output_dir = os.path.join(run_dir, task_name)
                stderr_log_path = os.path.join(output_dir, "stderr.log")
                hydra_run_dir = f"hydra.run.dir={output_dir}"

                task_specific_args = (
                    f"generation.gen_length={length} "
                    f"cache.rollout_p={p} "
                    f"cache.current_k={k}"
                )
                
                args = f"{exp1_base_args} {task_specific_args} {hydra_run_dir}"
                full_command = f"{base_command} -- {args}"
                tasks.append((full_command, stderr_log_path))

    # ==========================================================================
    # å®éªŒäºŒ: ç½‘æ ¼æœç´¢ cache.sigma
    # ==========================================================================
    print("--- æ­£åœ¨ç”Ÿæˆ [å®éªŒäºŒ: ç½‘æ ¼æœç´¢ sigma] ä»»åŠ¡ ---")
    # å®éªŒäºŒä¹Ÿå›ºå®šæ¨¡å‹ã€ç¼“å­˜å’Œæ•°æ®é›†
    exp2_base_args = f"{common_args} model=dream-inst cache=d2cache dataset.name=humaneval"
    gen_lengths_exp2 = [256, 1024]
    sigmas = [1.0, 10.0, 20.0, 40.0, 80.0]
    fixed_rollout_p = 0.1
    fixed_current_k = 32

    for length in gen_lengths_exp2:
        for sigma in sigmas:
            task_name = f"exp2_sigma_search/len{length}/sigma{sigma}"
            output_dir = os.path.join(run_dir, task_name)
            stderr_log_path = os.path.join(output_dir, "stderr.log")
            hydra_run_dir = f"hydra.run.dir={output_dir}"

            task_specific_args = (
                f"generation.gen_length={length} "
                f"cache.rollout_p={fixed_rollout_p} "
                f"cache.current_k={fixed_current_k} "
                f"cache.sigma={sigma}"
            )
            
            args = f"{exp2_base_args} {task_specific_args} {hydra_run_dir}"
            full_command = f"{base_command} -- {args}"
            tasks.append((full_command, stderr_log_path))
            
    # ==========================================================================
    # å®éªŒä¸‰: å¯¹æ¯”ä¸åŒæ¨¡å‹ã€æ•°æ®é›†å’Œç¼“å­˜ç­–ç•¥ (å·²æ›´æ–°)
    # ==========================================================================
    print("--- æ­£åœ¨ç”Ÿæˆ [å®éªŒä¸‰: å¯¹æ¯”æ¨¡å‹ã€æ•°æ®é›†å’Œç¼“å­˜ç­–ç•¥] ä»»åŠ¡ ---")
    exp3_models = ["dream-inst", "llada-inst"]
    exp3_caches = ["no_cache", "dllm", "prefix", "d2cache"]
    exp3_datasets = ["humaneval", "mbpp", "gsm8k", "math-500"] # æ–°å¢çš„æ•°æ®é›†åˆ—è¡¨
    exp3_gen_length = 1024

    for model in exp3_models:
        for dataset in exp3_datasets: # æ–°å¢æ•°æ®é›†å¾ªç¯
            for cache in exp3_caches:
                # æ›´æ–°ä»»åŠ¡å‘½åä»¥åŒ…å«æ•°æ®é›†
                task_name = f"exp3_model_cache_compare/{model}/{dataset}/{cache}"
                output_dir = os.path.join(run_dir, task_name)
                stderr_log_path = os.path.join(output_dir, "stderr.log")
                hydra_run_dir = f"hydra.run.dir={output_dir}"

                # ç‰¹æ®Šå¤„ç† no_cache çš„æƒ…å†µ
                if cache == "no_cache":
                    cache_arg = "" # å½“æ˜¯ no_cache æ—¶, ä¸æ·»åŠ  cache= å‚æ•°
                else:
                    cache_arg = f"cache={cache}"

                # ç»„åˆå‚æ•°ï¼Œç°åœ¨åŒ…å«åŠ¨æ€çš„æ•°æ®é›†åç§°
                args = (
                    f"{common_args} "
                    f"model={model} "
                    f"dataset.name={dataset} "
                    f"{cache_arg} "
                    f"generation.gen_length={exp3_gen_length} "
                    f"{hydra_run_dir}"
                )
                
                # æ¸…ç†å›  cache_arg ä¸ºç©ºå¯èƒ½äº§ç”Ÿçš„å¤šä½™ç©ºæ ¼
                args = ' '.join(args.split())

                full_command = f"{base_command} -- {args}"
                tasks.append((full_command, stderr_log_path))

    return tasks

# --- ä¸»è°ƒåº¦é€»è¾‘ (ä¿æŒä¸å˜) ---

def main(available_gpu_ids):
    """ä¸»å‡½æ•°ï¼Œç”¨äºè°ƒåº¦å’Œç®¡ç†ä»»åŠ¡"""

    gpus_per_task = len(available_gpu_ids)
    if gpus_per_task == 0:
        print("é”™è¯¯ï¼šæœªæŒ‡å®šä»»ä½• GPUã€‚è¯·ä½¿ç”¨ --gpus å‚æ•°æä¾› GPU IDã€‚")
        return
    print(f"æ£€æµ‹åˆ° {gpus_per_task} ä¸ªæŒ‡å®šçš„ GPUã€‚æ¯ä¸ªä»»åŠ¡å°†ä½¿ç”¨æ‰€æœ‰è¿™ {gpus_per_task} ä¸ª GPUã€‚")
    
    timestamp = time.strftime("%Y-%m-%d")
    run_dir = f"outputs/{timestamp}"
    print(f"æ‰€æœ‰å®éªŒè¾“å‡ºå°†ä¿å­˜åœ¨åŸºç›®å½•: {run_dir}")

    task_queue = generate_tasks(gpus_per_task, run_dir)
    total_tasks = len(task_queue)
    print(f"\næˆåŠŸç”Ÿæˆ {total_tasks} ä¸ªç‹¬ç«‹ä»»åŠ¡ã€‚")

    gpu_slot = available_gpu_ids
    slot_is_available = True
    running_process_info = None
    completed_tasks = 0

    while task_queue or running_process_info:
        if running_process_info:
            process, stderr_log_file = running_process_info
            if process.poll() is not None:
                exit_code = process.returncode
                stderr_log_file.close()

                print(f"âœ… ä»»åŠ¡ (PID: {process.pid}) å·²å®Œæˆï¼Œé€€å‡ºç : {exit_code}ã€‚é‡Šæ”¾ GPU æ’æ§½: {gpu_slot}")
                print(f"   - Stderr æ—¥å¿—å·²ä¿å­˜è‡³: {stderr_log_file.name}")
                slot_is_available = True
                if exit_code == 0:
                    completed_tasks += 1
                else:
                    print(f"âŒ è­¦å‘Šï¼šä»»åŠ¡ (PID: {process.pid}) å¼‚å¸¸é€€å‡ºï¼è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ã€‚")
                running_process_info = None

        if slot_is_available and task_queue:
            command_to_run, stderr_log_path = task_queue.popleft()

            env = os.environ.copy()
            env["CUDA_VISIBLE_DEVICES"] = ",".join(map(str, gpu_slot))

            print("-" * 60)
            print(f"ğŸš€ å‡†å¤‡å¯åŠ¨æ–°ä»»åŠ¡ ({total_tasks - len(task_queue)}/{total_tasks}):")
            print(f"   - å‘½ä»¤: {command_to_run}")
            print(f"   - ä½¿ç”¨ GPU: {gpu_slot} (CUDA_VISIBLE_DEVICES={env['CUDA_VISIBLE_DEVICES']})")
            print(f"   - Stderr å°†è¾“å‡ºåˆ°: {stderr_log_path}")

            os.makedirs(os.path.dirname(stderr_log_path), exist_ok=True)
            stderr_log_file = open(stderr_log_path, 'w')
            
            command_list = shlex.split(command_to_run)
            process = subprocess.Popen(
                command_list, 
                shell=False,
                env=env, 
                stderr=stderr_log_file
            )
            
            running_process_info = (process, stderr_log_file)
            slot_is_available = False

            print(f"   - ä»»åŠ¡å·²å¯åŠ¨ï¼ŒPID: {process.pid}")

        time.sleep(10)

    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²æ‰§è¡Œå®Œæ¯•ï¼")
    print(f"æ€»è®¡æˆåŠŸå®Œæˆ {completed_tasks}/{total_tasks} ä¸ªä»»åŠ¡ã€‚")
    print("=" * 60)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="GPU ä»»åŠ¡ç®¡ç†å™¨")
    parser.add_argument(
        "--gpus",
        type=str,
        default="0,1,2,3",
        help="æŒ‡å®šç”¨äºä»»åŠ¡è°ƒåº¦çš„ GPU ID åˆ—è¡¨ï¼Œä»¥é€—å·åˆ†éš”ã€‚ä¾‹å¦‚ '0,1,2,3'"
    )
    args = parser.parse_args()

    try:
        gpu_ids = [int(g.strip()) for g in args.gpus.split(',') if g.strip()]
    except ValueError:
        print("é”™è¯¯ï¼š--gpus å‚æ•°æ ¼å¼ä¸æ­£ç¡®ã€‚è¯·è¾“å…¥ä»¥é€—å·åˆ†éš”çš„æ•°å­—ï¼Œä¾‹å¦‚ '0,1,2,3'")
        exit(1)

    main(gpu_ids)